{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tech Challenge Fase 4 - Análise de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from insightface.app import FaceAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(emotion_counts, total_frames, output_path):\n",
    "    # Exibir Relatório no Console\n",
    "    print(\"RELATÓRIO:\")\n",
    "\n",
    "    # Exibir o total de frames analisados\n",
    "    print(f\"\\nTotal de frames analisados: {total_frames}\")\n",
    "\n",
    "    # Exibir o resumo das emoções detectadas\n",
    "    print(\"\\nResumo das emoções detectadas:\")\n",
    "    for emotion, count in emotion_counts.items():\n",
    "        print(f\"{emotion}: {count} ocorrências\")\n",
    "\n",
    "    # Exibir o número de anomalias detectadas (categorias 'Unknown')\n",
    "    anomalies = emotion_counts.get(\"Unknown\", 0)\n",
    "    print(f\"\\nNúmero de anomalias detectadas: {anomalies}\")\n",
    "\n",
    "    # Criar o arquivo de relatório\n",
    "    report_path = os.path.join(os.path.dirname(output_path), 'relatorio_analise.txt')\n",
    "    \n",
    "    with open(report_path, 'w') as report_file:\n",
    "        # Escrever o total de frames analisados\n",
    "        report_file.write(f\"Total de frames analisados: {total_frames}\\n\")\n",
    "        \n",
    "        # Escrever o resumo das emoções detectadas\n",
    "        report_file.write(\"\\nResumo das emoções detectadas:\\n\")\n",
    "        for emotion, count in emotion_counts.items():\n",
    "            report_file.write(f\"{emotion}: {count} ocorrências)\\n\")\n",
    "        \n",
    "        # Escrever o número de anomalias detectadas\n",
    "        report_file.write(f\"\\nNúmero de anomalias detectadas: {anomalies}\\n\")\n",
    "\n",
    "    print(f\"\\nRelatório salvo em: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotions(video_path, output_path):\n",
    "    # Capturar vídeo do arquivo especificado\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Verificar se o vídeo foi aberto corretamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Erro ao abrir o vídeo.\")\n",
    "        return\n",
    "\n",
    "    # Obter propriedades do vídeo\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Definir o codec e criar o objeto VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Inicializar dicionário para contabilizar emoções\n",
    "    emotion_counts = {}\n",
    "\n",
    "    app = FaceAnalysis()\n",
    "    app.prepare(ctx_id=0)  # Use ctx_id=-1 for CPU\n",
    "\n",
    "    # Loop para processar cada frame do vídeo\n",
    "    for _ in tqdm(range(total_frames), desc=\"Processando vídeo\"):\n",
    "        # Ler um frame do vídeo\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Se não conseguiu ler o frame (final do vídeo), sair do loop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "        faces = app.get(rgb_frame)\n",
    "\n",
    "        # Manter o controle do número de faces detectadas\n",
    "        if 'prev_num_faces' not in locals():\n",
    "            prev_num_faces = 0\n",
    "\n",
    "        num_faces = len(faces)\n",
    "\n",
    "        faces_text = f\"Number of faces changed from {prev_num_faces} to {num_faces}\"\n",
    "        cv2.putText(frame, faces_text, (10, height - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        if num_faces != prev_num_faces:\n",
    "            prev_num_faces = num_faces\n",
    "\n",
    "        for face in faces:\n",
    "            box = face.bbox.astype(int)\n",
    "\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "\n",
    "            face_roi = rgb_frame[box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "            try:\n",
    "\n",
    "                analysis = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "                if isinstance(analysis, list) and len(analysis) > 0:\n",
    "                    dominant_emotion = analysis[0]['dominant_emotion']\n",
    "                else:\n",
    "                    dominant_emotion = \"Unknown\"\n",
    "\n",
    "            except Exception as e:\n",
    "                dominant_emotion = \"Error\"\n",
    "                print(f\"Error analyzing emotion: {e}\")\n",
    "\n",
    "            # Atualizar contador de emoções\n",
    "            if dominant_emotion not in emotion_counts:\n",
    "                emotion_counts[dominant_emotion] = 0\n",
    "            emotion_counts[dominant_emotion] += 1\n",
    "\n",
    "            cv2.putText(frame, dominant_emotion, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "        # Escrever o frame processado no arquivo de vídeo de saída   \n",
    "        out.write(frame)\n",
    "\n",
    "    # Chamar a função para gerar o relatório\n",
    "    generate_summary(emotion_counts, total_frames, output_path)\n",
    "  \n",
    "    # Liberar a captura de vídeo e fechar todas as janelas\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo de vídeo na mesma pasta do script\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "input_video_path = os.path.join(script_dir, 'video_cut.mp4')\n",
    "output_video_path = os.path.join(script_dir, 'output_video_12.mp4')  # Nome do vídeo de saída\n",
    "\n",
    "# Chamar a função para detectar emoções no vídeo e salvar o vídeo processado\n",
    "detect_emotions(input_video_path, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
